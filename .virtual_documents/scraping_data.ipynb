


from bs4 import BeautifulSoup
import requests
import pandas as pd
pd.set_option('display.max_rows',None)


from selenium import webdriver
from selenium.webdriver.common.by import By
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from selenium.webdriver.edge.service import Service as EdgeService


pd.reset_option('display.max_rows')





url = 'https://riordan.fandom.com/wiki/Percy_Jackson_and_the_Olympians'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html')


print(soup.prettify)





driver = webdriver.Edge(service=EdgeService(EdgeChromiumDriverManager().install()))





div_content = soup.find('div', class_="wds-is-not-scrollable wds-dropdown-level-nested__content")


books = []

if div_content:
    # Find all <a> tags within the div
    a_tags = div_content.find_all('a')

    # Extract book name and URL, then append to the 'books' list
    for a in a_tags:
        book_name = a.find('span').text.strip()
        book_url = a.get('href')
        books.append({'book_name': book_name, 'url': book_url})


books





url = 'https://riordan.fandom.com/wiki/Category:Characters'
page = requests.get(url)
soup = BeautifulSoup(page.text, 'html')


print(soup)


soup.find('a', class_="category-page__pagination-next wds-button wds-is-secondary")


# creating a function that finds the url of the "Next" page and returns it
def get_next_page_url(soup):
    next_button = soup.find('a', class_="category-page__pagination-next wds-button wds-is-secondary")
    if next_button:
        return next_button.get('href')
    return None


url = 'https://riordan.fandom.com/wiki/Category:Characters'
driver.get(url)
time.sleep(10)

character_list = []

while True:
    page_source = driver.page_source
    soup = BeautifulSoup(page_source, 'html.parser')

    # getting all the character names and creating a list of them
    character_elems = soup.find_all(class_='category-page__member-link')
    for elem in character_elems:
        character_list.append({'character': elem.text})

    # getting the url of the "Next" page
    next_page_url = get_next_page_url(soup)

    # Break the loop if the "Next" button is not found(On last page)
    if not next_page_url:
        break

    # Navigate to the next page using the obtained URL
    driver.get(next_page_url)
    time.sleep(5) 


# Creating a dataframe for the list of character
df = pd.DataFrame(character_list)


df.to_csv('characters.csv', index=False)





df = df[~df['character'].str.contains(r'^User:', na=False)]
df = df[~df['character'].str.contains(r'^Category:', na=False)]
df = df[~df['character'].str.contains(r'^Template:', na=False)]
df = df[~df['character'].str.endswith('/Disney+', na=False)]
df = df[~df['character'].str.endswith('/Film', na=False)]
df['character_firstname'] = df['character'].apply(lambda x: x.split(' ', 1)[0])


df = df.reset_index(drop=True)
df


df.to_csv('characters.csv', index=False)
