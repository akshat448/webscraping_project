!pip install spacy networkx pyvis





import pandas as pd
import numpy as np
import spacy
from spacy import displacy
import networkx as nx
import matplotlib.pyplot as plt





!python -m spacy download en_core_web_sm


nlp = spacy.load("en_core_web_sm")





import os
 
# Get all book files in the data directory
all_books = [b for b in os.scandir('data') if '.txt' in b.name]


all_books


book = all_books[0]
book_text = open(book, encoding='utf-8').read()
book_doc = nlp(book_text)


# Visualize identified entities
displacy.render(book_doc[0:2000], style="ent", jupyter=True)





# dataframe containing list of character names
df = pd.read_csv('characters.csv')


df


sent_list = []
# looping through sentences and storing named entity list 
for sent in book_doc.sents:
    character_list = [ent.text for ent in sent.ents]
    sent_list.append({"sentence": sent, "Characters": character_list})
    
sent_df = pd.DataFrame(sent_list)


sent_df


# function that filters out a dataframe and returns only character names persent in a sentence
def char_filter(sent_df, df):
    return [char for char in sent_df 
            if char in list(df.character)
            or char in list(df.character_firstname)
           ]


char_filter(["Percy", "abc", "Annabeth"], df)


sent_df['character_name'] = sent_df['Characters'].apply(lambda x : char_filter(x, df))

# Filter out sentences that don't have any character entities
sent_df_filtered = sent_df[sent_df['character_name'].map(len) > 0]
sent_df_filtered.head(10)


# Take only first name of characters
sent_df_filtered['character_name'] = sent_df_filtered['character_name'].apply(lambda x: [item.split()[0] 
                                                                                         for item in x])


sent_df_filtered





window_size=5
relationships=[]

for i in range(sent_df_filtered.index[-1]):
    end_i = min(i+5,sent_df_filtered.index[-1])
    char_list = sum((sent_df_filtered.loc[i: end_i].character_name), [])

    # remove duplicated character names 
    char_unique = [char_list[i] for i in range(len(char_list))
                  if (i==0) or char_list[i] != char_list[i-1] ]

    if len(char_unique) > 1:
        for idx, a in enumerate(char_unique[:-1]):
            b = char_unique[idx+1]
            relationships.append({"source": a, "target": b})


relationship_df = pd.DataFrame(relationships)


pd.set_option('display.max_rows', None)
relationship_df


# sorting the relations to be in one order, a -> b
relationship_df = pd.DataFrame(np.sort(relationship_df.values, axis = 1), columns = relationship_df.columns)
relationship_df


# creating a weights column which will display the relationship frequency
relationship_df['value'] = 1
relationship_df = relationship_df.groupby(["source","target"],sort=False, as_index=False).sum()


relationship_df








# graph on the relations dataframe
gr = nx.from_pandas_edgelist(relationship_df,
                             source='source',
                             target='target',
                             edge_attr='value',
                             create_using=nx.Graph())


plt.figure(figsize=(10,10))
pos = nx.kamada_kawai_layout(gr)
nx.draw(gr, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos, font_size=12, font_color='red')
plt.show()





cdn_resources='in-line'


from pyvis.network import Network

net = Network(notebook = True, width="1500px", height="1000px", bgcolor='#222222', font_color='white')

node_degree = dict(gr.degree)

#Setting up node size attribute
nx.set_node_attributes(gr, node_degree, 'size')
# Disable physics simulation by setting physics to False
for node in gr.nodes:
    gr.nodes[node]['physics'] = False
for edge in gr.edges:
    gr.edges[edge]['physics'] = False

net.from_nx(gr)
net.show("percyjackson.html")





# Degree centrality
degree_dict = nx.degree_centrality(gr)
degree_dict


degree_df = pd.DataFrame.from_dict(degree_dict, orient='index', columns=['centrality'])
# Plot top 10 nodes
degree_df.sort_values('centrality', ascending=False)[0:9].plot(kind="bar")


# Betweenness centrality
betweenness_dict = nx.betweenness_centrality(gr)
betweenness_df = pd.DataFrame.from_dict(betweenness_dict, orient='index', columns=['centrality'])
# Plot top 10 nodes
betweenness_df.sort_values('centrality', ascending=False)[0:9].plot(kind="bar")


# Closeness centrality
closeness_dict = nx.closeness_centrality(gr)
closeness_df = pd.DataFrame.from_dict(closeness_dict, orient='index', columns=['centrality'])
# Plot top 10 nodes
closeness_df.sort_values('centrality', ascending=False)[0:9].plot(kind="bar")


# Save centrality measures
nx.set_node_attributes(gr, degree_dict, 'degree_centrality')
nx.set_node_attributes(gr, betweenness_dict, 'betweenness_centrality')
nx.set_node_attributes(gr, closeness_dict, 'closeness_centrality')





import community as community_louvain

communities = community_louvain.best_partition(gr)


communities


nx.set_node_attributes(gr, communities, 'group')


com_net = Network(notebook = True, width="1500px", height="900px", bgcolor='#222222', font_color='white')
com_net.from_nx(gr)
com_net.show("percyjackson_communities.html")
